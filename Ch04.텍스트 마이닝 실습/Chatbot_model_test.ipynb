{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot_model_test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1EusnhAg0A_-1-ECF2kEpJR02VN4pCddJ",
      "authorship_tag": "ABX9TyP/fHlt/8l6vo7RKNUIFYI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yukyung0622/Colab/blob/master/Ch04.%ED%85%8D%EC%8A%A4%ED%8A%B8%20%EB%A7%88%EC%9D%B4%EB%8B%9D%20%EC%8B%A4%EC%8A%B5/Chatbot_model_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sTY0k8ROSDQq"
      },
      "outputs": [],
      "source": [
        "#라이브러리 선언\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#토큰 불러오기\n",
        "with open('/content/drive/MyDrive/파이썬 데이터 과학 실습/file/chatbot_tokenizer.picle', 'rb') as handle:\n",
        "  tokenizer = pickle.load(handle)\n",
        "\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2cf5HszSZZJ",
        "outputId": "724294a7-1d70-4b75-aedb-7ca68dcb1fb3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras_preprocessing.text.Tokenizer at 0x7fc3c1a7ad10>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 불러오기\n",
        "model = load_model('/content/drive/MyDrive/파이썬 데이터 과학 실습/file/chatbot_model.h5')\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03bUlcWeTWBi",
        "outputId": "4b6970e4-4067-4cfd-935a-7c270d8ea65e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7fc3c241bb90>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#문장 생성 함수\n",
        "def sentence_generation(current_word):\n",
        "  init_word = current_word\n",
        "  sentence = ''\n",
        "\n",
        "  while True:\n",
        "    encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
        "    encoded = pad_sequences([encoded], maxlen=20, padding='pre')\n",
        "\n",
        "    #입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
        "    result = model.predict(encoded, verbose=0)\n",
        "    result = np.argmax(result, axis=1)\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      #만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
        "      if index == result:\n",
        "        break\n",
        "\n",
        "    if word == '<end>':\n",
        "      break\n",
        "\n",
        "    #현재단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
        "    current_word = current_word + ' ' +word\n",
        "\n",
        "    #예측단어를 문장에 저장\n",
        "    sentence = sentence + ' ' + word\n",
        "\n",
        "  sentence = init_word+'--->'+sentence\n",
        "\n",
        "  return sentence\n",
        "\n",
        "#테스트\n",
        "print(sentence_generation('12시 땡!'))\n",
        "print(sentence_generation('코 막혀'))\n",
        "print(sentence_generation('무슨 말을 해야할까'))\n",
        "print(sentence_generation('안녕'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSHV42l-Tc5K",
        "outputId": "15b84456-0f49-43a4-d6ea-b0804065feff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12시 땡!---> 하루가 또 가네요\n",
            "코 막혀---> 감기 조심하세요\n",
            "무슨 말을 해야할까---> 하고 싶은 말 다하세요\n",
            "안녕---> 안녕하세요\n"
          ]
        }
      ]
    }
  ]
}